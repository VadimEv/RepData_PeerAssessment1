sapply(flag_colors, mean)
flag_shapes <- flags[,19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,5,6,6))
unique_vals <- lapply(flags, unique)
unique_vals
sapply(unique_vals,lenght)
sapply(unique_vals,length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
str(plants)
head(plants)
head(plants,nrows=10)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6,4, replace=TRUE)
sample(1:6,4, replace=TRUE)
sample(1:20,10, replace=FALSe)
sample(1:20,10, replace=FALSE)
sample(1:20,10)
LETTERS
sample(LETTERS)
flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2<-rbinom(1, size = 100, prob = 0.7)
flips2<-rbinom(100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,mean=100, sd=25)
rpois(5, 10)
my_pois<-replicate(100, rpois(5, 10))
my_pois
cm<colMeans(my_pois)
cm<-colMeans(my_pois)
hist(cm)
d1<-Sys.Date()
class(d1)
unclass(d1)
d1
d2<-as.Date("1969-01-01")
unclass(d2)
Sys.time()
t1<-Sys.time()
t1
class(t1)
unclass(t1)
t2<-as.POSIXlt(Sys.time())
t2
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarters(t2)
t3<- "October 17, 1986 08:24"
strptime(t3, "%B %d, %Y %H:%M")
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time()>t1
Sys.time()-t1
difftime(Sys.time(), t1, units = 'days')
data(cars)
help(cars)
head(cars)
plot(cars)
plot()
help(plot)
plot(x = cars$speed, y = cars$dist)
plot(x = cars$dist, y = cars$speed)
plot(x = "Speed", y = cars$speed)
plot(x = cars$dist, y = cars$speed, "Speed")
plot(x = cars$dist, y = cars$speed, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(cars, main ="My Plot")
plot(cars, sub ="My Plot Subtitle")
plot(cars, col =2)
plot(cars, xlim = c(10, 15))
plot(cars, pch = 2)
data(mtcars)
?bxplot
??bxplot
?boxplot
boxplot(mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf<-read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(r_arch:country, cran)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5,20)
-(5:20)
cran
select(cran, -(X:size))
filter(cran, package="swirl")
filter(cran, package=="swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparision
?Comparison
filter(cran, r_version == "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 && r_os == "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2<-select(size:ip_id)
cran2<-select(size,ip_id)
cran2<-select(cran,size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size +1000)
summarize(cran, avg_bytes = mean(size))
bye()
library(XML)
install.packages("XML")
library(XML)
file_url <- "http://www.w3schools.com/xml/simple.xml"
doc<-xmlTreeParse(file_url,usInternal = T)
doc<-xmlTreeParse(file_url,usInternal = TRUE)
doc<-xmlTreeParse(file_url,useInternal = TRUE)
rootnode<-xmlRoot(doc)
xmlNmae(rootnode)
xmlName(rootnode)
names(rootnoe)
names(rootnode)
rootnode[[1]]
xmlSapply(rootnode, xmlValue)
xmlSApply(rootnode, xmlValue)
xpathSApply(rootnode, "//name",xmlValue)
xpathSApply(rootnode, "//price",xmlValue)
xpathSApply(rootnode, "//calories",xmlValue)
library(data.table)
install.package(data.table)
install.packages("data.table")
library(data.table)
DF=data.frame(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9))
head(DF)
DF=data.table(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9))
DT=data.frame(x=rnorm(9),y=rep(c("a","b","c"),each=3),z=rnorm(9))
head(DT,3)
tbales()
tables()
DT[2,]
DT[DT$y='a']
DT[DT$y=="a"]
DT[DT$y=="a",]
DT[c(2,3)]
DT[,c(2,3)]
DT[,list(mean(x), sum(z))]
DF[,list(mean(x), sum(z))]
DF[,m:={tmp <- (x+z), log2(tmp+5)}]
DF[,m:={tmp <- (x+z); log2(tmp+5)}]
DF
tmp_q<-download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv)
tmp_q<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
?download.file
download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv, tmp_q.csv)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", tmp_q.csv)
file.create(tmp_q.cs)
file.create(tmp_q.csv)
file.create("tmp_q.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", tmp_q.csv)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "tmp_q.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "tmp_q.csv", lynx)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "tmp_q.csv", "lynx")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "tmp_q.csv", "curl")
DT < - read.csv(tmp_q.csv)
DT < - read.csv(tmp_q)
list.files()
DT < - read.csv(tmp_q.csv)
DT < - read.csv("tmp_q.csv")
?data.table
DT <-read.table("tmp_q.csv",header=TRUE,sep=",")
head(DT)
DT[,c("val")]
DT[,c("VAL")]
DT[,c("VAL")>= 24 ]
filter(DT, VAL >= 24)
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- xmlRoot(doc)
sum(xpathSApply(rootNode, "//zipcode", xmlValue)==21231)
memory(doc)
dim(doc)
memory(doc)
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
View(by_package)
summarize(by_package, mean(size))
reset()
submit()
pack_sum
bye()
library(httr)
myapp <- oauth_app("github", "ClientID", "ClientSecret")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/rate_limit", config(token = github_token))
content(req)
BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
hurl <- "http://biostat.jhsph.edu/~jleek/contact.html"
con <- url(hurl)
htmlCode <- readLines(con)
close(con)
sapply(htmlCode[c(10, 20, 30, 100)], nchar)
?read.fwf
swirl()
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pac_sum, count >679)
top_counts <- filter(pack_sum, count >679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, count ="desc")
?desc
?arrange
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted(top_unique, desc(unique))
top_unique_sorted<-arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
source('/var/folders/fb/_4b72v0503s0km40y4lkfmmr0000gn/T//RtmpP45Hnz/chain1.R')
nxt()
countries = n_distinct(country),
?select
select(contains("ip_id"), country, package, size) %>%
select(ip_id, country, package, size) %>%
select(ip_id, country, package, size) %>%
source('/var/folders/fb/_4b72v0503s0km40y4lkfmmr0000gn/T//RtmpP45Hnz/chain1.R')
print
print()
source('/var/folders/fb/_4b72v0503s0km40y4lkfmmr0000gn/T//RtmpP45Hnz/chain1.R')
print(result)
nxt
skip()
mutate(size_mb = size / 2^20)
source('/var/folders/fb/_4b72v0503s0km40y4lkfmmr0000gn/T//RtmpP45Hnz/chain2.R')
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students,sex,count, -grade)
students2
bye()
rm(mydf)
url <- https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
?download.file
getwd()
a <- download.file(url, idaho.csv, curl)
a <- download.file(url, "idaho.csv", curl)
a <- download.file(url, "idaho.csv", "curl")
ls
?list.files
list.files(getwd())
idata <- read.csv(idaho.csv)
idata <- read.csv("idaho.csv")
head(idata)
agriculture.logical <- idata$AGS == 6 & idata$ACR == 3
which(agriculture.logical)[1:3]
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg "
a <- download.file(url, "jeff.jpg", "curl")
?read.jpg
??read.jpg
?jpeg
img <- jpeg("jeff.jpg")
head(img)
list.files(getwd())
img <- readJPEG("jeff.jpg")
img <- read.JPEG("jeff.jpg")
img <- readJPEG("jeff.jpg", native=TRUE)
?readjpeg
?readJPG
readJPEG
?readJPEG
? read jpeg
?read jpeg
install.packages("jpeg")
library(jpeg)
?readJPEG
img <- read.JPEG("jeff.jpg", native = TRUE)
img <- readJPEG("jeff.jpg", native = TRUE)
?qunatile
?quantile
quantile(img, probs = c(0.3, 0,8))
quantile(img, probs = c(0.3, 0.8))
library(dplyr)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv "
download.file(url, "gdp190.csv", "curl")
df1 <- read.csv("gdp190.csv")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url, "edu.csv", "curl")
df2 <- read.csv("edu.csv")
?match
head(df1)
class(X$df1)
class(df1$X)
class(df1$X.1)
summary(df1)
str(df1)
str(df2)
?merge
df <-merge(df1,df2, all = TRUE, by = c('CountryCode'))
df <-merge(df1,df2, all = TRUE, by = c("CountryCode"))
df <-merge(df1,df2, all = TRUE, by = c("CountryCode"))
swirl()
swirl
info()
install.packages("swirl")
swirl()
library(swirl)
swirl()
swirl()
swirl()
install_from_swirl("Getting_and_Cleaning_Data")
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, col = sex_class, into = c("sex", "class"))
submit()
students3
submit()
source('/var/folders/fb/_4b72v0503s0km40y4lkfmmr0000gn/T//RtmpQYikSV/script2.R')
submit()
submit()
?spread()
?spread
submit()
submit()
submit()
submit()
submit()
submit()
submit()
extract_numeric("class5")
?mutate
submit()
submit()
submit()
students4
submit()
?unique
submit()
submit()
submit()
submit()
submit()
passed
failed
mutate(passed, status = c("passed"))
passed < - passed %>% mutate(status = c("passed"))
passed < - passed %>% mutate(status = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
?bind_rows
bind_rows(passed, failed)
sat
?select
?separate
submit()
?group_by
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
day(this_day)
wday(this_day)
wday(this_day, label=TRUE)
this_moment <- now()
this_moment
minute(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("19/20/12")
ymd("1920/1/2"
)
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment)
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
?now
nyc <- now(tzone="America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34, seconds = 0)
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tz = "Asia/Hong_Kong")
arrive
last_time <- with_tz(mdy("June 17, 2008"), tz = "Singapore")
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long<- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
getwd()
setwd("/Volumes/Flashko/RepData")
getwd()
ls
dir
DT < - read.csv(activity.csv)
DT <- read.csv(activity.csv)
getwd()
DT <- read.csv("activity.csv")
head(DT)
DTdailysum <- aggregate(DT$steps, list(DT$date), sum)
?list
list(DT$date)
DTmean <- mean(DTdailysum, na.rm = TRUE)
DTmean <- mean(DTdailysum$steps, na.rm = TRUE)
DTmean <- mean(DTdailysum$step, na.rm = TRUE)
DTmean <- mean(DTdailysum$steps, na.rm = TRUE)
DTdailysum
DTmean <- mean(DTdailysum$x, na.rm = TRUE)
DTmean
head(DTdailysum)
